{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Modelo yolo, treinamentos e testes de resultado\n",
        "\n"
      ],
      "metadata": {
        "id": "L_l654BTkJLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PG0WkmfokTEN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive   # integração drive e colab\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "id": "aPcKqUrBlMDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -r yolov5/requirements.txt   # instalando requirements para rodar yolo"
      ],
      "metadata": {
        "id": "BT5Vi7YllMKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e591c65a"
      },
      "source": [
        "yaml_content = \"\"\"\n",
        "train: /content/drive/MyDrive/FIAP/FIAP_NEXT/2025/images/train/\n",
        "val: /content/drive/MyDrive/FIAP/FIAP_NEXT/2025/images/val/\n",
        "\n",
        "nc: 2 # number of classes\n",
        "names: # Define here the labels of your dataset\n",
        "  0: \"Mouse\"\n",
        "  1: \"Controle\"\n",
        "\"\"\"\n",
        "\n",
        "with open(\"MouseControle1.yaml\", \"w\") as f:\n",
        "    f.write(yaml_content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python yolov5/train.py --data MouseControle1.yaml --weights yolov5s.pt --img 640 --epochs 60   # testes com 40 e depois 60 epochs"
      ],
      "metadata": {
        "id": "4LeFRtMIlMOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rodando testes de acurácia\n",
        "\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "def get_latest_train_run_folder():\n",
        "    subfolders = [f.path for f in os.scandir('yolov5/runs/train') if f.is_dir()]\n",
        "    latest_folder = max(subfolders, key=os.path.getctime, default=None)\n",
        "    return latest_folder\n",
        "\n",
        "latest_run = get_latest_train_run_folder()\n",
        "result = subprocess.run(f'python yolov5/detect.py --weights {latest_run}/weights/best.pt --img 640 --source drive/MyDrive/FIAP/FIAP_NEXT/2025/images/test/ --data yolov5/data/MouseControle1.yaml', shell=True, capture_output=True, text=True)\n",
        "if latest_run:\n",
        "    # COMANDO\n",
        "    result = subprocess.run(f'python yolov5/detect.py --weights {latest_run}/weights/best.pt --img 640 --source drive/MyDrive/FIAP/FIAP_NEXT/2025/images/test/ --data yolov5/data/MouseControle1.yaml', shell=True, capture_output=True, text=True)\n",
        "    print(result.stdout)\n",
        "    print(result.stderr)\n",
        "else:\n",
        "    print(\"Não foi possível encontrar a pasta de treinamento mais recente.\")"
      ],
      "metadata": {
        "id": "A3c2L1RZlMVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.CNN para classificar classe de imagens"
      ],
      "metadata": {
        "id": "JPA9Q3D5kH9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q ultralytics # ultralytics fornece APIs de YOLO modernas (v8) e permite treino/avaliação fáceis\n",
        "!pip install -q yolov5 # utilitário que pode ajudar se preferir YOLOv5\n",
        "!pip install -q tensorflow\n",
        "!pip install -q opencv-python-headless\n",
        "!pip install -q seaborn matplotlib scikit-learn pandas\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "W5typMg2kBYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "DATASET_PATH = Path('/content/dataset') # ajuste se necessário\n",
        "IMG_DIR = DATASET_PATH / 'images'\n",
        "LABELS_DIR = DATASET_PATH / 'labels'"
      ],
      "metadata": {
        "id": "gHfe6WyXkBV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for p in [IMG_DIR / 'train', IMG_DIR / 'val', LABELS_DIR / 'train', LABELS_DIR / 'val']:\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "print('Dataset root:', DATASET_PATH)\n",
        "print('Train images example dir:', IMG_DIR / 'train')"
      ],
      "metadata": {
        "id": "iODu1TSvkBKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO_ADAPTAVEL_WEIGHTS = '/content/entrega1_weights.pt' # substitua pelo seu arquivo .pt se existir\n",
        "from ultralytics import YOLO\n",
        "if os.path.exists(YOLO_ADAPTAVEL_WEIGHTS):\n",
        "    model_adapt = YOLO(YOLO_ADAPTAVEL_WEIGHTS)\n",
        "    print('Modelo adaptável carregado:', YOLO_ADAPTAVEL_WEIGHTS)\n",
        "else:\n",
        "    model_adapt = None\n",
        "    print('Nenhum peso adaptável encontrado; deixe YOLO_ADAPTAVEL_WEIGHTS apontar para seu .pt')"
      ],
      "metadata": {
        "id": "MVT3lp97kBHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_adapt is not None:\n",
        "    example_img = next((IMG_DIR / 'val').glob('*.jpg'), None)\n",
        "    if example_img:\n",
        "        print('Executando inferência em:', example_img)\n",
        "        res = model_adapt.predict(str(example_img))\n",
        "        display(res[0].plot())\n",
        "    else:\n",
        "        print('Nenhuma imagem de validação encontrada para inferência de exemplo.')\n",
        "else:\n",
        "    print('Pule esta célula — modelo adaptável não está disponível.')"
      ],
      "metadata": {
        "id": "5PHj5csJkBFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_data_yaml = {\n",
        "'path': str(DATASET_PATH),\n",
        "'train': 'images/train',\n",
        "'val': 'images/val',\n",
        "'nc': 1, # número de classes; altere se tiver mais classes\n",
        "'names': ['classe0'] # altere para os nomes reais das classes\n",
        "}\n",
        "\n",
        "\n",
        "import yaml\n",
        "with open('data.yaml', 'w') as f:\n",
        "    yaml.dump(yolo_data_yaml, f)\n",
        "\n",
        "\n",
        "print('Arquivo data.yaml criado. Confira nc e names antes de treinar!')"
      ],
      "metadata": {
        "id": "Z196LpzvkA9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui usamos a API Ultralytics para treinar um modelo 'yolov8n' (pequeno, rápido). Se quiser usar yolov5, comente e use a seção alternativa.\n",
        "\n",
        "EPOCHS = 30\n",
        "BATCH = 8\n",
        "IMG_SIZE = 640\n",
        "MODEL_NAME = 'yolov8n.pt' # modelo pequeno pré-treinado (Ultralytics)"
      ],
      "metadata": {
        "id": "7M4Nx5KpkArQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute o treino (pode demorar — adapte EPOCHS/BATCH)\n",
        "from ultralytics import YOLO\n",
        "model_baseline = YOLO(MODEL_NAME)\n"
      ],
      "metadata": {
        "id": "dhDF9f0Xl-Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Treine; os resultados ficam em ./runs/train\n",
        "\n",
        "print('Iniciando treino YOLO baseline — ajuste EPOCHS/BATCH/IMG_SIZE conforme o seu ambiente')\n",
        "model_baseline.train(data='data.yaml', epochs=EPOCHS, imgsz=IMG_SIZE, batch=BATCH, name='baseline_yolo')"
      ],
      "metadata": {
        "id": "a_38yue-l-SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliar o modelo treinado (usa val set definido em data.yaml)\n",
        "\n",
        "results = model_baseline.val() # retorna dicionário com métricas, incluindo mAP\n",
        "print('Métricas do YOLO baseline:')\n",
        "print(results)"
      ],
      "metadata": {
        "id": "0TxOhy-jl-Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salve pesos finais para comparação\n",
        "\n",
        "baseline_weights = 'runs/train/baseline_yolo/weights/best.pt'\n",
        "print('Pesos salvo em:', baseline_weights)"
      ],
      "metadata": {
        "id": "0DJelsuDl-Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "\n",
        "IMG_SIZE_CLS = (128,128)\n",
        "BATCH_CLS = 32\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=15, width_shift_range=0.1,\n",
        "height_shift_range=0.1, horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(str(CROPS_DIR/'train'), target_size=IMG_SIZE_CLS, batch_size=BATCH_CLS, class_mode='categorical')\n",
        "val_generator = val_datagen.flow_from_directory(str(CROPS_DIR/'val'), target_size=IMG_SIZE_CLS, batch_size=BATCH_CLS, class_mode='categorical')\n",
        "\n",
        "\n",
        "NUM_CLASSES = train_generator.num_classes\n",
        "print('Número de classes (classification):', NUM_CLASSES)"
      ],
      "metadata": {
        "id": "pCUMIGEml-LB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir e treinar uma CNN simples do zero\n",
        "\n",
        "from tensorflow.keras import layers, models, optimizers, callbacks\n",
        "\n",
        "\n",
        "def build_simple_cnn(input_shape=(128,128,3), num_classes=NUM_CLASSES):\n",
        "model = models.Sequential([\n",
        "layers.Conv2D(32,3,activation='relu',input_shape=input_shape),\n",
        "layers.MaxPooling2D(2),\n",
        "layers.Conv2D(64,3,activation='relu'),\n",
        "layers.MaxPooling2D(2),\n",
        "layers.Conv2D(128,3,activation='relu'),\n",
        "layers.MaxPooling2D(2),\n",
        "layers.Flatten(),\n",
        "layers.Dense(128,activation='relu'),\n",
        "layers.Dropout(0.5),\n",
        "layers.Dense(num_classes,activation='softmax')\n",
        "])\n",
        "model.compile(optimizer=optimizers.Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "return model\n",
        "\n",
        "\n",
        "cnn_model = build_simple_cnn()\n",
        "cnn_model.summary()\n",
        "\n",
        "\n",
        "\n",
        "EPOCHS_CLS = 25\n",
        "callbacks_list = [callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
        "history = cnn_model.fit(train_generator, validation_data=val_generator, epochs=EPOCHS_CLS, callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "\n",
        "cnn_model.save('cnn_from_scratch.h5')\n",
        "print('Modelo de classificação salvo como cnn_from_scratch.h5')"
      ],
      "metadata": {
        "id": "C9vbkc3Il-I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Avaliação da CNN e matrizes\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "Prever no val set\n",
        "val_generator.reset()\n",
        "preds = cnn_model.predict(val_generator)\n",
        "y_pred = np.argmax(preds, axis=1)\n",
        "y_true = val_generator.classes\n",
        "\n",
        "\n",
        "print('Classification report:')\n",
        "print(classification_report(y_true, y_pred, target_names=list(val_generator.class_indices.keys())))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print('Matriz de confusão:\\n', cm)"
      ],
      "metadata": {
        "id": "DQ559weZl-Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "\n",
        "\n",
        "def measuretime(fn, inputs, repeat=20):\n",
        "times = []\n",
        "for  in range(repeat):\n",
        "start = time.time()\n",
        "fn(inputs)\n",
        "times.append(time.time()-start)\n",
        "return float(np.mean(times)), float(np.std(times))"
      ],
      "metadata": {
        "id": "HToL4V3Pl-B7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Medir inferência YOLO baseline\n",
        "\n",
        "if 'model_baseline' in globals() and model_baseline is not None:\n",
        "sample_imgs = list((IMG_DIR/'val').glob('.jpg'))[:10]\n",
        "def runyolo(imgs):\n",
        "for p in imgs:\n",
        " = model_baseline.predict(str(p), verbose=False)\n",
        "mean_yolo, std_yolo = measure_time(run_yolo, sample_imgs, repeat=3)\n",
        "print(f'YOLO baseline — tempo médio (para {len(sample_imgs)} imgs): {mean_yolo:.3f}s (std {std_yolo:.3f})')\n",
        "else:\n",
        "print('Modelo YOLO baseline não disponível para medir tempo.')\n"
      ],
      "metadata": {
        "id": "xUp_Tulkl99d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Medir inferência CNN (classificação)\n",
        "\n",
        "sample_img = next((CROPS_DIR/'val').glob('**/.jpg'), None)\n",
        "if sample_img is not None:\n",
        "import PIL.Image as Image\n",
        "img = Image.open(sample_img).resize(IMG_SIZE_CLS)\n",
        "arr = np.array(img)/255.0\n",
        "def runcnn():\n",
        "_ = cnn_model.predict(np.expand_dims(arr,0))\n",
        "mean_cnn, std_cnn = measure_time(run_cnn, None, repeat=20)\n",
        "print(f'CNN classificação — tempo médio por imagem: {mean_cnn:.4f}s (std {std_cnn:.4f})')\n",
        "else:\n",
        "print('Não há crops para medir inferência da CNN.')"
      ],
      "metadata": {
        "id": "GIqTDdMvl97B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}